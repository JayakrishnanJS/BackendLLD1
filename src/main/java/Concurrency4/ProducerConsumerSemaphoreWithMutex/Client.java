package Concurrency4.ProducerConsumerSemaphoreWithMutex;

import java.util.concurrent.Semaphore;

public class Client {
    // corrected main that uses the new, fullyâ€‘encapsulated Store APIâ€”no external semaphores,
    // no manual mutex, just clean producer/consumer threads:
    public static void main(String[] args) {
        Store store = new Store(5);
        //Semaphore mutex = new Semaphore(1);
        //Semaphore producerSemaphore = new Semaphore(store.getMaxSize());
        //Semaphore consumerSemaphore = new Semaphore(0);


        for(int i = 0; i < 8; i++){
            //Producer producer = new Producer(store, producerSemaphore, consumerSemaphore);
            //new Thread(producer).start();
            Producer producer = new Producer(store);
            new Thread(producer, "Producer-" + i).start();
        }

        for(int i = 0; i < 20; i++){
            //Consumer consumer = new Consumer(store, producerSemaphore, consumerSemaphore);
            //new Thread(consumer).start();
            Consumer consumer = new Consumer(store);
            new Thread(consumer, "Consumer-" + i).start();
        }
    }
}
/**
    Why this is â€œclassic bounded bufferâ€:

    1. emptySlots starts at the bufferâ€™s capacity; producers block when full.
    2. availableItems starts at 0; consumers block when empty.
    3. mutex (binary semaphore) ensures only one thread at a time manipulates the queue.
    4. tryâ€¦finally around mutex.acquire()/release() guarantees you never deadlock if something
       inside the critical section throws.

    A finiteâ€size container (the â€œbounded bufferâ€) holds items produced by one or more producer threads
    and consumed by one or more consumer threads. Because it has limited capacity, producers must wait
    if itâ€™s full, and consumers must wait if itâ€™s empty.

    Role of mutex
    1. Guarantees Exclusive Access: Only one thread at a time can be inside the â€œcritical sectionâ€ that
       touches the queue. This prevents two producers (or a producer and a consumer) from simultaneously
       calling items.add(...) or items.poll().

    2. Prevents Race Conditions: Without mutual exclusion, you can get interleaved operations like:
        a. One thread reads size(), another thread modifies the queue, then the first thread proceeds
           with an incorrect assumption.
        b Two threads updating internal pointers or counters inside the queue at the same time,
          leading to corruption or lost elements.

    3. Keeps Queue Invariants Intact
        Most queue implementations (even threadâ€‘safe ones like ConcurrentLinkedQueue) assume that
        single operations (add(), poll()) are atomicâ€”but if you combine size checks plus removes/adds,
        you need a lock to make those multiâ€‘step operations safe.
**/


/*
| Approach                                    | Use Case                                         | Thread Coordination | Fineâ€‘grained Control | Ease of Use | Performance  | Strengths                                                  | Drawbacks                                                           |
| ------------------------------------------- | ------------------------------------------------ | ------------------- | -------------------- | ----------- | ------------ | ---------------------------------------------------------- | ------------------------------------------------------------------- |
| `synchronized` method                       | Entireâ€‘method mutual exclusion                   | âŒ                   | âŒ                    | âœ…           | ðŸŸ¨ Medium    | Very simple, builtâ€‘in, no extra classes                    | Locks entire method, no timeout/interrupt, potential to overâ€‘lock   |
| `synchronized` block                        | Criticalâ€‘section locking only                    | âŒ                   | âœ…                    | âœ…           | ðŸŸ© Better    | Limits lock scope, minimal boilerplate                     | No tryâ€‘lock or fairness options                                     |
| `wait()` / `notify()`                       | Lowâ€‘level thread signaling on object monitor     | âœ…                   | ðŸŸ¨ Medium            | ðŸŸ¨ Complex  | ðŸŸ¨ Medium    | Fineâ€‘grained condition waiting, no extra classes           | Errorâ€‘prone (missed notify, lost wakeups), must use in synchronized |
| `ReentrantLock`                             | Advanced locking (tryLock, timed, interruptible) | âœ…                   | âœ…                    | ðŸŸ¥ Verbose  | ðŸŸ© High      | Supports fairness, tryLock, multiple `Condition`s          | More verbose than `synchronized`                                    |
| `ReadWriteLock`                             | Many readers, few writers                        | âœ…                   | âœ…                    | ðŸŸ¨ Moderate | ðŸŸ© High      | Maximizes concurrency for readâ€‘heavy workloads             | Writers can starve readers or vice versa if misconfigured           |
| `Semaphore`                                 | Counting access control (permits for resources)  | âœ…                   | âœ…                    | ðŸŸ¨ Moderate | ðŸŸ© High      | Controls number of concurrent users, simple pattern        | No builtâ€‘in mutual exclusion on shared data                         |
| `BlockingQueue` (e.g. `ArrayBlockingQueue`) | Producerâ€‘consumer queues, buffer management      | âœ…                   | âœ…                    | âœ…           | ðŸŸ© Very high | Builtâ€‘in blocking, threadâ€‘safe, simple usage               | Fixed capacity must be chosen carefully                             |
| `CountDownLatch`                            | Oneâ€‘time/oneâ€‘shot thread coordination            | âœ…                   | âŒ                    | âœ…           | ðŸŸ© High      | Simplest barrier for â€œwait for N to finishâ€                | Cannot be reset once count reaches zero                             |
| `CyclicBarrier`                             | Reusable barrier for N threads                   | âœ…                   | âŒ                    | âœ…           | ðŸŸ© High      | Automatically resets, supports barrier actions             | All parties must arrive; exceptions if one thread fails             |
| `Phaser`                                    | Dynamic, multiâ€‘phase barriers                    | âœ…                   | âœ…                    | ðŸŸ¨ Moderate | ðŸŸ© High      | Like reusable `CountDownLatch` + `CyclicBarrier`           | More complex API                                                    |
| `ExecutorService` / Thread pools            | Managing worker threads & task queues            | âœ…                   | âŒ                    | âœ…           | ðŸŸ© Very high | Simplifies thread lifecycle, tuneable pool sizes           | Overhead of task submission, need to shut down cleanly              |
| `ScheduledExecutorService`                  | Delayed or periodic task execution               | âœ…                   | âŒ                    | âœ…           | ðŸŸ© Very high | Builtâ€‘in scheduling, no manual timer threads               | Limited flexibility vs. external schedulers                         |
| `CompletableFuture` / reactive streams      | Asynchronous callbacks and data flows            | âœ…                   | âœ…                    | ðŸŸ¨ Moderate | ðŸŸ© High      | Composable, nonâ€‘blocking pipelines                         | Learning curve, can obscure threading context                       |
| `StampedLock`                               | Optimistic read/write with version stamps        | âœ…                   | âœ…                    | ðŸŸ¥ Verbose  | ðŸŸ© Very high | Extremely fast for readâ€‘heavy loads with infrequent writes | Complex to use correctly                                            |
*/